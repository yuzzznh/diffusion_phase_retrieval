# My Project: LatentDAPSë¡œ Langevin Dynamics sampling + TDP-style íƒìƒ‰ìœ¼ë¡œ 0Â° 180Â° ì°¾ê¸° + ë§¨ ë§ˆì§€ë§‰ hard data consistency ì ìš©

## ì‹¤í—˜ë³„ ëª…ë ¹ì–´

``` bash
# ============================================================
# GPU (CUDA) ëª…ë ¹ì–´ - commands_gpu/ í´ë”
# ============================================================
# ì‹¤í—˜ 0
bash commands_gpu/exp0_baseline.sh --1           # 1 image sanity check
bash commands_gpu/exp0_baseline.sh --10          # 10 images
bash commands_gpu/exp0_baseline.sh --100         # 100 images
bash commands_gpu/exp0_baseline.sh --1 --10      # 1 + 10 images ìˆœì°¨ ì‹¤í–‰

# ì‹¤í—˜ 1~4
bash commands_gpu/exp1_repulsion.sh --1 --10 --100
bash commands_gpu/exp2_pruning.sh --1 --10 --100
bash commands_gpu/exp3_2particle.sh --10 --100    # (1 image ì—†ìŒ)
bash commands_gpu/exp4_optimization.sh --1 --10 --100

# ì‹¤í—˜ 5
bash commands_gpu/exp5_final.sh --imagenet        # ImageNet 100
bash commands_gpu/exp5_final.sh --ffhq            # FFHQ 100
bash commands_gpu/exp5_final.sh --imagenet --ffhq # ë‘˜ ë‹¤

# ============================================================
# TPU (GCP TPU v3-8) ëª…ë ¹ì–´ - commands_tpu/ í´ë”
# ============================================================
# ì‹¤í—˜ 0
bash commands_tpu/exp0_baseline.sh --1           # 1 image sanity check
bash commands_tpu/exp0_baseline.sh --10          # 10 images
bash commands_tpu/exp0_baseline.sh --100         # 100 images

# ì‹¤í—˜ 1~4
bash commands_tpu/exp1_repulsion.sh --1 --10 --100
bash commands_tpu/exp2_pruning.sh --1 --10 --100
bash commands_tpu/exp3_2particle.sh --10 --100
bash commands_tpu/exp4_optimization.sh --1 --10 --100

# ì‹¤í—˜ 5
bash commands_tpu/exp5_final.sh --imagenet
bash commands_tpu/exp5_final.sh --ffhq
bash commands_tpu/exp5_final.sh --imagenet --ffhq

# ============================================================
# ì¸ì ì—†ì´ ì‹¤í–‰í•˜ë©´ ì‚¬ìš©ë²• ì¶œë ¥:
# ============================================================
$ bash commands_gpu/exp0_baseline.sh
# ì‚¬ìš©ë²•: bash exp0_baseline.sh [--1] [--10] [--100]
# --1   : 1 image sanity check
# --10  : 10 images main experiment
# --100 : 100 images final eval

# ============================================================
# ì§ì ‘ python ëª…ë ¹ì–´ ì‹¤í–‰ ì‹œ TPU/CUDA ì„ íƒ
# ============================================================
# CUDA (ê¸°ë³¸ê°’)
python posterior_sample.py ... use_tpu=false

# TPU (GCP TPU v3-8)
python posterior_sample.py ... use_tpu=true
```

## ì‹¤í—˜ ì§„í–‰ ë° êµ¬í˜„ ê³¼ì • ì„¤ê³„

### [ë°ì´í„°] imagenet 10ì¥ìœ¼ë¡œ method ë¹„êµ, ë§ˆì§€ë§‰ evalì€ ffhq imagenet 100ì¥ì”©ìœ¼ë¡œ í•˜ëŠ”ê±¸ ëª©í‘œë¡œ, ì—¬ê±´ ì•ˆë˜ë©´ ffhqëŠ” ë²„ë¦¬ê¸° / ì‹œë“œ ê³ ì • (ì´ë¯¸ DAPSì—ì„œëŠ” 42)

### [ì‹¤í—˜ 0] LatentDAPS ë…¼ë¬¸ì— eval ë°ì´í„°ëŠ” 100 imageì—ë§Œ ë‚˜ì™€ìˆìœ¼ë‹ˆê¹Œ ë¹„êµë¥¼ ìœ„í•´ LatentDAPS(with Langevin Dynamic)ì˜ imagenet first 10 imageì— ëŒ€í•œ phase retrieval ì„±ëŠ¥ ì¸¡ì •.
- ~~ë‹¨, ì´ë•Œ imageë³„ë¡œ ì „ë¶€ ëŒì•„ê°„ ë’¤ ë‹¤ìŒ runì´ ì‹¤í–‰ë˜ëŠ” êµ¬ì¡°ë¡œ 4 runì´ êµ¬í˜„ë¼ìˆëŠ”ë°, ì´í›„ ì‹¤í—˜ë“¤ê³¼ì˜ ì›í™œí•œ ë¹„êµë¥¼ ìœ„í•´ eval ëª…ë ¹ì–´ë¥¼ 4 batch = 4 run êµ¬ì¡°ë¡œ ë³€ê²½í•´ì•¼ í•¨.~~
- ~~time logging: diffusion timestep Të¥¼ êµ¬ê°„ê°œìˆ˜ë¡œ í•˜ì—¬ **timestepë³„ ì†Œìš” ì‹œê°„**ì„ ì¸¡ì •. ì´í›„ ì‹¤í—˜ì—ì„œ pruning/optimization ì‹œì  ì „í›„ ì‹œê°„ ë¹„êµì— í™œìš©. sanity check ì°¨ì›ì—ì„œ 1 image 4 sample ëª…ë ¹ì–´ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸í•  ê²ƒ.~~ â†’ **ì™„ë£Œ**: `sampler.py`ì˜ `LatentDAPS.sample()`ì—ì„œ stepë³„ ì‹œê°„ ì¸¡ì • (`self.timing_info`ì— ì €ì¥), `posterior_sample.py`ì—ì„œ ì´ë¯¸ì§€ë³„ timing ì§‘ê³„ í›„ `metrics.json`ì— ì €ì¥.
- ~~GPU VRAM logging: ì‹¤í—˜ 0ì—ì„œëŠ” phase êµ¬ë¶„ ì—†ì´ **ì „ì²´ êµ¬ê°„ì˜ peak VRAM**ë§Œ ì¸¡ì •. `torch.cuda.max_memory_allocated()` í™œìš©.~~ â†’ **ì™„ë£Œ**: `posterior_sample.py`ì—ì„œ `torch.cuda.reset_peak_memory_stats()` í›„ `torch.cuda.max_memory_allocated()` ì¸¡ì •, `metrics.json`ì˜ `metadata.gpu.peak_vram_mb`ì— ì €ì¥. (phaseë³„ êµ¬ê°„ ë¶„ë¦¬ëŠ” ì‹¤í—˜ 2, 4ì—ì„œ pruning/optimization ì¶”ê°€ ì‹œ êµ¬í˜„)
- ~~ëª…ë ¹ì–´ ìë™ê¸°ë¡ ë©”ì»¤ë‹ˆì¦˜ì´ ì´ë¯¸ ìˆëŠ”ê±¸ë¡œ ì•„ëŠ”ë°, ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ íŒŒì•…í•˜ê³ , ìš°ë¦¬ ì‹¤í—˜ 0~5ì˜ ê°ì¢… argument ì„¸íŒ…ì´ ì˜ ê¸°ë¡ë˜ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•  ê²ƒ.~~ â†’ **Hydra ê¸°ë°˜ config ìë™ê¸°ë¡ í™•ì¸ ì™„ë£Œ**: `posterior_sample.py`ì—ì„œ `OmegaConf.to_container(args)`ë¥¼ í†µí•´ ëª¨ë“  configê°€ mergeëœ ìµœì¢… ê²°ê³¼ë¥¼ `results/<name>/config.yaml`ì— ìë™ ì €ì¥í•¨. sh ëª…ë ¹ì–´ì—ì„œ overrideí•œ ëª¨ë“  argumentê°€ ê¸°ë¡ë¨.
- **TPU ì§€ì› êµ¬í˜„ ì™„ë£Œ** (`use_tpu` flag): GCP TPU v3-8 (PyTorch XLA) í™˜ê²½ì—ì„œë„ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ì½”ë“œ ìˆ˜ì •.
    1. `utils/device.py` ì¤‘ì•™í™”: ëª¨ë“  TPU/CUDA ë¶„ê¸° ë¡œì§ì„ í•œ ê³³ì—ì„œ ê´€ë¦¬ (`get_device()`, `setup_device()`, `mark_step()` ë“±)
    2. `mark_step()` ìë™ í˜¸ì¶œ: `sampler.py`ì˜ sampling loop ë§¤ step ëì—ì„œ í˜¸ì¶œ â†’ TPU lazy execution ê·¸ë˜í”„ ì‹¤í–‰ (ë©”ëª¨ë¦¬ í­ë°œ ë°©ì§€)
    3. ë©”ëª¨ë¦¬ ì¸¡ì •: TPUëŠ” `xm.get_memory_info()`, CUDAëŠ” `torch.cuda.max_memory_allocated()` ì‚¬ìš© â†’ `metrics.json`ì˜ `metadata.device`ì— ì €ì¥

### [ì‹¤í—˜ 1] 4-Particle Full Run (Repulsion vs. Independence)
* ì„¤ì •: ì…ì 4ê°œ, ì²˜ìŒë¶€í„° ëê¹Œì§€($T \to 0$) ìœ ì§€.
* ë¹„êµ: Ours (Repulsion ON) vs. DAPS Baseline (Repulsion OFF, Independent)
* í™•ì¸í•  ì§€í‘œ:
    * Max PSNR: 4ê°œ ì¤‘ ê°€ì¥ ì˜ ë‚˜ì˜¨ ë†ˆì˜ ì ìˆ˜. (ìš°ë¦¬ê°€ ë” ë†’ê±°ë‚˜ ë¹„ìŠ·í•´ì•¼ í•¨)
    * Std / Mode Coverage: 4ê°œê°€ 0ë„, 180ë„, í˜¹ì€ ë‹¤ë¥¸ Local Minimaë¡œ ì–¼ë§ˆë‚˜ ì˜ í©ì–´ì¡ŒëŠ”ê°€?
        * DAPS: ìš´ ë‚˜ì˜ë©´ 4ê°œ ë‹¤ 0ë„ë¡œ ì ë¦¼.
        * Ours: 0ë„, 180ë„ ê³¨ê³ ë£¨ ë‚˜ì™€ì•¼ ì„±ê³µ.
* ê¸°ëŒ€ ê²°ë¡ : "ë‹¨ìˆœíˆ ì—¬ëŸ¬ ë²ˆ ëŒë¦¬ëŠ” ê²ƒ(DAPS)ë³´ë‹¤, ì„œë¡œ ë°€ì–´ë‚´ë©° ëŒë¦¬ëŠ” ê²ƒ(Ours)ì´ ì •ë‹µ(Global Optima)ì„ ì°¾ì„ í™•ë¥ (Success Rate)ì´ í›¨ì”¬ ë†’ë‹¤."
* ì—¬ê¸°ì—ì„  particle guidanceë¥¼ ì˜ ì½”ë”©í•˜ê³  repulsion ê°•ë„ ë“± hyperparameter ê°’ì„ ì ì ˆí•˜ê²Œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ê´€ê±´. 
* ì´ì— ëŒ€í•œ sanity check ë° ê°€ì¥ ê¸°ë³¸ì ì¸ ê²½í–¥ì„± ì²´í¬ë¥¼ ìœ„í•´ 1 image 4 (particle) run ëª…ë ¹ì–´ë¥¼ ì ê·¹ í™œìš©í•œ ë’¤ ë””ë²„ê¹… ì™„ë£Œëœ ì½”ë“œë² ì´ìŠ¤ì—ì„œ í•©ë¦¬ì ì¸ hyperparameter setìœ¼ë¡œ 10 image ì‹¤í—˜ì„ ëŒë¦¬ì.
âš ï¸ ì£¼ì˜í•  ì  (Manifold):
* Repulsionì„ ìœ„í•´ z.gradë¥¼ ì¡°ì‘í•  ë•Œ, ë„ˆë¬´ ê°•í•˜ê²Œ ë°€ë©´ Latentê°€ í•™ìŠµëœ ë¶„í¬ ë°–(Off-manifold)ìœ¼ë¡œ íŠ•ê²¨ ë‚˜ê°€ ì´ë¯¸ì§€ê°€ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ì´ˆë°˜ì—ëŠ” ê°•í•˜ê²Œ, í›„ë°˜($t \to 0$)ìœ¼ë¡œ ê°ˆìˆ˜ë¡ 0ì— ìˆ˜ë ´í•˜ë„ë¡ Decay Scheduleì„ ê¼­ ë„£ìœ¼ì„¸ìš”.
ğŸ’¡ íŒ (Sanity Check):
* 1 Image ì‹¤í—˜ ì‹œ, 4ê°œì˜ Latent Vector ê°„ì˜ **í‰ê·  ê±°ë¦¬(Average Pairwise Distance)**ë¥¼ ë§¤ ìŠ¤í… ë¡œê¹…í•˜ì„¸ìš”.
* Baseline(ë…ë¦½ ì‹¤í–‰)ë³´ë‹¤ ì´ ê±°ë¦¬ê°€ í™•ì‹¤íˆ ì»¤ì•¼ ì„±ê³µì…ë‹ˆë‹¤.

### [ì‹¤í—˜ 2] 4 â†’ 2 Pruning (Efficiency Verification)
* ì„¤ì •: 4ê°œë¡œ ì‹œì‘ $\to$ $t=200$ì—ì„œ 2ê°œë¡œ ì••ì¶• $\to$ ë.
* ë¹„êµ: Exp 2 (Pruning) vs. Exp 1 (Full Run)
* í™•ì¸í•  ì§€í‘œ:
    * Max PSNR ìœ ì§€ ì—¬ë¶€: Exp 1ê³¼ ê²°ê³¼ê°€ ê±°ì˜ ë˜‘ê°™ì•„ì•¼ í•¨. (ë–¨ì–´ì§€ë©´ Pruning ë¡œì§ ì‹¤íŒ¨)
    * Time / Memory: ì‹œê°„ì´ ì–¼ë§ˆë‚˜ ë‹¨ì¶•ë˜ì—ˆëŠ”ê°€? (ì´ê²Œ ë…¼ë¬¸ì˜ ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸)
* ê¸°ëŒ€ ê²°ë¡ : "ì´ˆë°˜ íƒìƒ‰ í›„ ê°€ë§ ì—†ëŠ” ë†ˆì„ ë²„ë ¤ë„ ì„±ëŠ¥ ì†ì‹¤ì€ ì—†ë‹¤. ì¦‰, Exp 1ì²˜ëŸ¼ ëê¹Œì§€ 4ê°œë¥¼ ëŒê³  ê°€ëŠ” ê±´ ìì› ë‚­ë¹„ë‹¤."
* pruning ì„ê³„ê°’ ë° timestepê³¼ ê°™ì€ hyperparameter ê°’ì„ ì ì ˆí•˜ê²Œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ê´€ê±´. ì´ì— ëŒ€í•œ sanity check ë° ê°€ì¥ ê¸°ë³¸ì ì¸ ê²½í–¥ì„± ì²´í¬ë¥¼ ìœ„í•´ 1 image 4 (particle) run ëª…ë ¹ì–´ë¥¼ ì ê·¹ í™œìš©í•œ ë’¤ ë””ë²„ê¹… ì™„ë£Œëœ ì½”ë“œë² ì´ìŠ¤ì—ì„œ í•©ë¦¬ì ì¸ hyperparameter setìœ¼ë¡œ 10 image ì‹¤í—˜ì„ ëŒë¦¬ì.
âš ï¸ ì£¼ì˜í•  ì  (Indexing Hell):
* ë°°ì¹˜ ì‚¬ì´ì¦ˆê°€ 4ì—ì„œ 2ë¡œ ì¤„ì–´ë“¤ ë•Œ, zë¿ë§Œ ì•„ë‹ˆë¼ optimizerì˜ state, schedulerì˜ step, measurement y ë“± ê´€ë ¨ëœ ëª¨ë“  ë³€ìˆ˜ë¥¼ ê°™ì´ ì¤„ì—¬ì•¼(Slicing) ì—ëŸ¬ê°€ ì•ˆ ë‚©ë‹ˆë‹¤.
* í—·ê°ˆë¦¬ë©´ ê·¸ëƒ¥ 4ê°œ ìœ ì§€ë¥¼ í•˜ë˜, íƒˆë½í•œ 2ê°œì— ëŒ€í•´ì„œëŠ” Gradient ê³„ì‚°ì„ ë„ëŠ” ë§ˆìŠ¤í‚¹(Masking) ì²˜ë¦¬ë§Œ í•´ë„ ì—°ì‚°ëŸ‰ ì´ë“ì€ ì¦ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë©”ëª¨ë¦¬ ì´ë“ì€ ì—†ì§€ë§Œ êµ¬í˜„ì€ ì‰¬ì›€) $\rightarrow$ í•˜ì§€ë§Œ ì§„ì§œ ë©”ëª¨ë¦¬ ì´ë“ì„ ìœ„í•´ Slicingì„ ì¶”ì²œí•©ë‹ˆë‹¤.
ğŸ“Š GPU VRAM ì¸¡ì • êµ¬ê°„ ë¶„ë¦¬ (êµ¬í˜„ í•„ìš”):
* Pruning ì¶”ê°€ ì‹œ, VRAM ì¸¡ì •ì„ **pruning ì „/í›„ ë‘ êµ¬ê°„**ìœ¼ë¡œ ìª¼ê°œì•¼ í•¨.
* `torch.cuda.reset_peak_memory_stats()`ë¥¼ pruning ì‹œì ì— í˜¸ì¶œí•˜ì—¬ ê° êµ¬ê°„ë³„ peakë¥¼ ë…ë¦½ ì¸¡ì •.
* metrics.jsonì— `vram.pre_pruning_peak_mb`, `vram.post_pruning_peak_mb` í˜•íƒœë¡œ ê¸°ë¡.

### [ì‹¤í—˜ 3] 2-Particle Full Run (Justification for '4')
* ì„¤ì •: ì²˜ìŒë¶€í„° 2ê°œë§Œ ë„ì›Œì„œ ëê¹Œì§€($T \to 0$) ìœ ì§€.
* ë¹„êµ: Exp 2 (4 $\to$ 2 Pruning) vs. Exp 3 (Just 2)
* í•µì‹¬ ì§ˆë¬¸: "ê·¸ëƒ¥ ì²˜ìŒë¶€í„° 2ê°œë§Œ ëŒë¦¬ë©´ ì•ˆ ë¼? êµ³ì´ 4ê°œë¡œ ì‹œì‘í•´ì„œ ì¤„ì—¬ì•¼ í•´?" (ë¦¬ë·°ì–´ë“¤ì´ ë¬´ì¡°ê±´ ë¬¼ì–´ë³¼ ì§ˆë¬¸)
* í™•ì¸í•  ì§€í‘œ:
    * Success Rate (ì„±ê³µë¥ ): Exp 3ì€ ê°€ë” ë‘˜ ë‹¤ ì‹¤íŒ¨(Local Minima)í•˜ëŠ” ê²½ìš°ê°€ ìƒê²¨ì•¼ í•¨. ë°˜ë©´ Exp 2ëŠ” 4ê°œ ì¤‘ ê³¨ëìœ¼ë¯€ë¡œ ì„±ê³µë¥ ì´ ë” ë†’ì•„ì•¼ í•¨.
* ê¸°ëŒ€ ê²°ë¡ : "ì²˜ìŒë¶€í„° 2ê°œë§Œ ì“°ë©´(Exp 3) ë¶ˆì•ˆì •í•˜ë‹¤. 4ê°œë¡œ ë„“ê²Œ íƒìƒ‰í•˜ê³  ì¤„ì´ëŠ” ê²ƒ(Exp 2)ì´ ì•ˆì •ì„±(Stability) ì¸¡ë©´ì—ì„œ í›¨ì”¬ ìš°ì›”í•˜ë‹¤."
* ì „ëµ: ì—¬ê¸°ì„œ ì‹¤íŒ¨ ì‚¬ë¡€(0ë„/180ë„ ëª¨ë‘ ëª» ì°¾ê³  Local Minima ë¹ ì§)ê°€ ë‹¨ í•˜ë‚˜ë¼ë„ ë‚˜ì˜¤ë©´ ë‹˜ì˜ ë…¼ë¦¬ëŠ” ì™„ë²½í•´ì§‘ë‹ˆë‹¤.
* ì‚¬ì‹¤ ì—¬ê¸°ì„  ì•ì„  ì‹¤í—˜ë“¤ì—ì„œ ì¶”ê°€ë˜ëŠ” hyperparameterê°€ ì—†ìœ¼ë©°, sampleë“¤ ì¤‘ ì‹¤íŒ¨í•˜ëŠ” ê²ƒë“¤ì˜ ë¹„ìœ¨ì„ ì œëŒ€ë¡œ ì¬ëŠ” ê²ƒì´ ê´€ê±´ì´ë¯€ë¡œ 1 image ì‹¤í—˜ì´ ì˜ë¯¸ê°€ ì—†ë‹¤. ìµœì†Œí•œ 10 image, ì—¬ê±´ì´ ë˜ë©´ 100 image ì‹¤í—˜ì„ ëŒë¦¬ì.

### [ì‹¤í—˜ 4] ì‹¤í—˜ 1~3 ì¤‘ ê°€ì¥ ì˜ ë‚˜ì˜¨ ì„¸íŒ…ì— ëŒ€í•´ ReSampleì˜ hard data consistency in latent space optimizationì„ ëŒë¦¬ì
- ì •í™•í•œ íšŸìˆ˜ ë° ê¸°ì¤€ì€ ReSample ê³µì‹ ë ˆí¬ì˜ êµ¬í˜„ì—ì„œ ì‹¤ì œ ëª‡ ë²ˆì˜ optimizationì´ ì´ë£¨ì–´ì§€ëŠ”ì§€ë¥¼ ì°¸ê³ í•´ì„œ ê²°ì •í•˜ì. hyperparameter íŠœë‹ì— 1 image ì‹¤í—˜ì„ í™œìš©í•˜ì.
- optimization íšŸìˆ˜ ë° ì†Œìš”ì‹œê°„ì„ ë³´ê³ í•˜ì. batch element ê°„ optimization ë° terminationì´ independentí•´ì•¼ í•¨ì— ìœ ì˜í•˜ì (ReSample ê³µì‹ ë ˆí¬ëŠ” ê·¸ë ‡ì§€ ì•Šì•˜ìŒ!)
ğŸ“Š GPU VRAM ì¸¡ì • êµ¬ê°„ ë¶„ë¦¬ (êµ¬í˜„ í•„ìš”):
* Optimization ì¶”ê°€ ì‹œ, VRAM ì¸¡ì •ì„ **optimization ì „/í›„ ë‘ êµ¬ê°„**ìœ¼ë¡œ ë¶„ë¦¬í•´ì•¼ í•¨.
* `torch.cuda.reset_peak_memory_stats()`ë¥¼ optimization ì‹œì‘ ì‹œì ì— í˜¸ì¶œí•˜ì—¬ ê° êµ¬ê°„ë³„ peakë¥¼ ë…ë¦½ ì¸¡ì •.
* metrics.jsonì— `vram.pre_optimization_peak_mb`, `vram.optimization_peak_mb` í˜•íƒœë¡œ ê¸°ë¡.
* ë§Œì•½ ì‹¤í—˜ 2ì˜ pruningê³¼ í•¨ê»˜ ì‚¬ìš© ì‹œ, 3êµ¬ê°„ìœ¼ë¡œ ë¶„ë¦¬: `pre_pruning`, `post_pruning_pre_optimization`, `optimization`.

### [ì‹¤í—˜ 5] ê²°ê³¼ë¥¼ ë³´ê³  ì œì¼ ì˜ ë‚˜ì˜¨ ì„¸íŒ…ì— ëŒ€í•´ 100 image ì‹¤í—˜ì„ ëŒë¦¬ì. 
- ì´í›„ particle guidance, ìœ ì „ì•Œê³ ë¦¬ì¦˜ì  ê´€ì ì˜ ì„¤ëª…, phase retrieval with 2 oversamplingì´ë¼ëŠ” 2-mode task ìì²´ì˜ íŠ¹ìˆ˜ì„±, DAPSì™€ ReSampleê³¼ì˜ ì‹¤í–‰ì‹œê°„ ë° GPU ë° ì—°ì‚°ëŸ‰ ë¹„êµ
- ëª‡ particleì´ í•„ìš”í–ˆê³  pruning ë° hard data consistency optimizationì´ ì–¼ë§ˆë‚˜ ë„ì›€ì´ ëëŠ”ì§€ì— ëŒ€í•œ ë³´ê³ 
- ê°€ëŠ¥í•˜ë©´ ffhq 100 imageì— ëŒ€í•´ì„œë„ evalì„ ì§„í–‰í•˜ì—¬ table ë§Œë“¤ê¸°.
* FFHQ 100ì¥: ì‹œê°„ì´ ë‚¨ìœ¼ë©´ ëŒë¦¬ë˜, ì•ˆ ë˜ë©´ "ImageNetì´ ë” ìƒìœ„ í˜¸í™˜(Superset) ë¬¸ì œì´ë¯€ë¡œ ìƒëµí–ˆë‹¤"ê³  í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.
* ìŠ¤í† ë¦¬í…”ë§: "ìœ ì „ ì•Œê³ ë¦¬ì¦˜ì  ê´€ì "ê³¼ "TDPì˜ Planning ê´€ì "ì„ ì„ì–´ì„œ ì„¤ëª…í•˜ë©´, ë‹¨ìˆœí•œ ì—”ì§€ë‹ˆì–´ë§ì´ ì•„ë‹ˆë¼ **'ìƒì„± ëª¨ë¸ì„ ìœ„í•œ íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜ ì œì•ˆ'**ìœ¼ë¡œ ê²©ìƒë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.



## êµ¬í˜„ ì˜ˆì‹œ. êµ¬ì²´ì ì¸ particle ìˆ˜ì™€ pruning ì—¬ë¶€ ë“±ì€ ì‹¤í—˜ 2~4 ì„¸ë¶€ ì„¤ì •ì— ë”°ë¦„.

### Phase 1: ì´ˆê¸° íƒìƒ‰ì—ì„œ Particle Guidance (PG)ë¥¼ í†µí•œ "ê°•ì œì  ë‹¤ì–‘ì„±" í™•ë³´
* ê¸°ì¡´ DAPSì˜ í•œê³„: DAPSëŠ” ê°œë³„ ìƒ˜í”Œ(Chain)ì´ ë…ë¦½ì ìœ¼ë¡œ MCMCë¥¼ ìˆ˜í–‰í•œë‹¤. ìš°ì—°íˆ ì´ˆê¸°í™”ê°€ ì˜ ë˜ë©´ ì„œë¡œ ë‹¤ë¥¸ í•´ë¥¼ ì°¾ì„ ìˆ˜ë„ ìˆì§€ë§Œ, ëŒ€ë¶€ë¶„ì€ ê°€ì¥ 'ì‰¬ìš´' í•´(Dominant Mode)ë¡œ ë‹¤ ê°™ì´ ì ë ¤ë²„ë¦¬ëŠ” ê²½í–¥ì´ ìˆë‹¤.
* êµ¬ê°„: T=000 ~ 200 (ì•½ 80% êµ¬ê°„)
* ë™ì‘: LatentDAPS + Particle Guidance (Repulsive Force) - ì—¬ëŸ¬ ê°œì˜ ê¶¤ì (Particle)ì„ ë™ì‹œì— ìƒì„±í•˜ë©´ì„œ, ì…ìë“¤ë¼ë¦¬ ì„œë¡œ ë°€ì–´ë‚´ëŠ” í˜(Repulsive Force)ì„ ì ìš©. ìœ ì‚¬ë„(Similarity)ì— ëŒ€í•œ í˜ë„í‹°
* ëª©ì : parent ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” ë‘ particleì´ ì„œë¡œ ë°€ì–´ë‚´ë©° í•´ ê³µê°„ì„ íƒìƒ‰í•©ë‹ˆë‹¤. í•˜ë‚˜ê°€ Mode 0Â°ë¡œ ê°€ë©´, ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ê°•ì œë¡œ Mode 180Â° ìª½ìœ¼ë¡œ ê°€ê²Œ ë©ë‹ˆë‹¤. í•´ ê³µê°„(Solution Space)ì„ í›¨ì”¬ ë„“ê²Œ ì»¤ë²„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ReSample ìµœì í™”: OFF (ì´ë•Œ ìµœì í™”í•˜ë©´ Local Minimaì— ë¹ ì§‘ë‹ˆë‹¤).

ğŸ’¡ ë³´ì™„ ì œì•ˆ (Annealing the Repulsion):
* ë¬¸ì œì : Repulsive Forceê°€ ë„ˆë¬´ ëê¹Œì§€ ìœ ì§€ë˜ë©´, ë‘ ì…ìê°€ ì„œë¡œë¥¼ ë°€ì–´ë‚´ëŠë¼ ì •ì‘ ë°ì´í„° ë§¤ë‹ˆí´ë“œ(Manifold) ì •ì¤‘ì•™(ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ì´ë¯¸ì§€)ì— ë„ë‹¬í•˜ì§€ ëª»í•˜ê³  ì•½ê°„ ë¹—ê²¨ë‚œ(Off-manifold) ìƒíƒœê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* í•´ê²°ì±…: TDP ë…¼ë¬¸ì—ì„œë„ ì–¸ê¸‰í•˜ë“¯, ì´ˆê¸°(High Noise)ì—ëŠ” $\alpha_p$(Particle Guidance Scale)ë¥¼ í¬ê²Œ ê°€ì ¸ê°€ì„œ í™•ì‹¤í•˜ê²Œ ê°ˆë¼ë†“ê³ , $t_{mid}$ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ $\alpha_p$ë¥¼ ì„œì„œíˆ ì¤„ì—¬ì„œ(Decay) ì…ìë“¤ì´ ê°ìì˜ Basin(ìˆ˜ë ´ ì˜ì—­) ì•ˆì°©í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
* ì´ˆê¸° ë¶„ê¸°(Bifurcation)ì˜ ì¤‘ìš”ì„±: Phase Retrievalì—ì„œ 0ë„/180ë„ ê²°ì •ì€ ë…¸ì´ì¦ˆê°€ ë§¤ìš° í° ì´ˆë°˜ ë‹¨ê³„ì—ì„œ ê²°ì •ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ˆë°˜ 20~30% êµ¬ê°„ì—ì„œì˜ PG ê°•ë„ê°€ ìŠ¹íŒ¨ë¥¼ ê°€ë¥¼ ê²ƒì…ë‹ˆë‹¤.


### Phase 2:  Bi-level Tree Structureë¥¼ í†µí•œ Global Optima íƒìƒ‰ ì¤‘ ê°€ì§€ì¹˜ê¸° (Pruning)
Phase Retrievalì€ ëŒ€í‘œì ì¸ Non-convex(ë¹„ë³¼ë¡) ìµœì í™” ë¬¸ì œë¡œ, ì˜ëª»ëœ ì´ˆê¸°ê°’ì—ì„œ ì‹œì‘í•˜ë©´ Local Minimaì— ë¹ ì ¸ ì˜ì˜ ëª» ë‚˜ì˜¬ ìœ„í—˜ì´ í½ë‹ˆë‹¤.
* ê¸°ì¡´ DAPSì˜ í•œê³„: DAPSëŠ” Noise Annealingì„ í†µí•´ ì´ë¥¼ ê·¹ë³µí•˜ë ¤ í•˜ì§€ë§Œ, í•˜ë‚˜ì˜ ê¶¤ì (Sequential)ë§Œ ë”°ë¼ê°€ê¸° ë•Œë¬¸ì— ë§Œì•½ ì´ˆë°˜(tê°€ í´ ë•Œ)ì— ì˜ëª»ëœ ë°©í–¥(Local Basin)ìœ¼ë¡œ ë“¤ì–´ì„œë©´ ë˜ëŒë¦¬ê¸° ì–´ë µë‹¤.
* TDPì˜ í•´ê²°ì±… (Parent Branching & Sub-tree Expansion): TDPëŠ” "Parent Trajectory(ë¶€ëª¨ ê¶¤ì )"ë¥¼ ë¨¼ì € ë‹¤ì–‘í•˜ê²Œ ë¿Œë ¤ë†“ê³ (Exploration), ê°€ëŠ¥ì„± ìˆì–´ ë³´ì´ëŠ” ê°€ì§€ì—ì„œ "Child Trajectory(ìì‹ ê¶¤ì )"ë¥¼ ë»—ì–´ ë‚˜ê°€ë©° ì •ë°€í•˜ê²Œ ë‹¤ë“¬ëŠ”ë‹¤(Exploitation).
    * Phase Retrieval ì ìš©:
        1. Parent ë‹¨ê³„ (t: T \to t_{mid}): Particle Guidanceë¥¼ ì¼œê³  DAPSë¥¼ ìˆ˜í–‰í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ "ëŒ€ëµì ì¸ í˜•íƒœ(Coarse Structure)"ë¥¼ ê°€ì§„ ì—¬ëŸ¬ í›„ë³´êµ°ì„ í™•ë³´í•©ë‹ˆë‹¤.
        2. Child ë‹¨ê³„ (t: t_{mid} \to 0): ê° Parentì—ì„œ ê°€ì§€ë¥¼ ì³ì„œ, ì´ì œëŠ” Repulsive Forceë¥¼ ë„ê³  ê°•ë ¥í•œ Data Consistency(ì¸¡ì •ê°’ ì¼ì¹˜)ë¥¼ ì ìš©í•´ ì •ë°€í•œ ì´ë¯¸ì§€ë¥¼ ë³µì›í•©ë‹ˆë‹¤.
    * ì´ ë°©ì‹ì€ ë‹¨ìˆœíˆ í•˜ë‚˜ì˜ ê¸¸ë§Œ ê°€ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì—¬ëŸ¬ ê°€ëŠ¥ì„±ì„ ë™ì‹œì— íƒìƒ‰í•˜ë‹¤ê°€ ìœ ë§í•œ ê³³ì„ ì§‘ì¤‘ ê³µëµí•˜ë¯€ë¡œ Global Optimaë¥¼ ì°¾ì„ í™•ë¥ ì´ ë¹„ì•½ì ìœ¼ë¡œ ìƒìŠ¹í•©ë‹ˆë‹¤.
* ì‹œì : T=200 ê·¼ì²˜
* ë™ì‘: ë‘ ì…ìì˜ measurement lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
* ê²°ì •:
    * ë‘˜ ë‹¤ Lossê°€ ë‚®ë‹¤ë©´? ë‘˜ ë‹¤ ì‚´ë¦½ë‹ˆë‹¤ (í•˜ë‚˜ëŠ” 0Â°, í•˜ë‚˜ëŠ” 180Â°ì¼ í™•ë¥  ë†’ìŒ).
    * í•˜ë‚˜ê°€ ì••ë„ì ìœ¼ë¡œ ë‚®ë‹¤ë©´? ë‚˜ìœ ë…€ì„ì„ ë²„ë¦¬ê³  ì¢‹ì€ ë…€ì„ì„ ë³µì œí•˜ê±°ë‚˜, ì¢‹ì€ ë…€ì„ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    * ì¤‘ê°„ ë‹¨ê³„(t_{mid})ì—ì„œ "ì´ ê°€ì§€ëŠ” ê°€ë§ì´ ì—†ë‹¤(Lossê°€ ë„ˆë¬´ í¬ë‹¤)" ì‹¶ìœ¼ë©´ ê°€ì§€ì¹˜ê¸°(Pruning)ë¥¼ í•´ë²„ë¦´ ìˆ˜ ìˆë‹¤.
    * ë‚¨ëŠ” ìì›ì„ ìœ ë§í•œ ê²½ë¡œì— ì§‘ì¤‘(Child Expansion)í•  ìˆ˜ ìˆìœ¼ë‹ˆ ê³„ì‚° ë¹„ìš© ëŒ€ë¹„ ì„±ëŠ¥(ROI)ì´ í›¨ì”¬ ë†’ë‹¤.

ğŸ’¡ ë³´ì™„ ì œì•ˆ (Diversity-aware Pruning):
* ì‹œë‚˜ë¦¬ì˜¤: ë§Œì•½ ë‘ ì…ì(A, B)ê°€ ìš´ ë‚˜ì˜ê²Œ ë‘˜ ë‹¤ 0ë„ ëª¨ë“œë¡œ ìˆ˜ë ´í–ˆëŠ”ë°, Aê°€ lossê°€ ë” ë‚®ë‹¤ê³  ì¹©ì‹œë‹¤. ë‹¨ìˆœíˆ lossë§Œ ë³´ë©´ Bë¥¼ ë²„ë¦¬ê² ì§€ë§Œ, ë§Œì•½ Bê°€ 180ë„ ëª¨ë“œë¡œ ê°€ëŠ” ì¤‘ì´ì—ˆë‹¤ë©´(ì•„ì§ lossëŠ” ë†’ì§€ë§Œ), Bë¥¼ ì‚´ë¦¬ëŠ” ê²Œ ë‚˜ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
* ì „ëµ: ê°€ì§€ì¹˜ê¸°ë¥¼ í•  ë•Œ ë‹¨ìˆœíˆ Lossë§Œ ë³¼ ê²ƒì´ ì•„ë‹ˆë¼, ë‘ ì…ì ê°„ì˜ ê±°ë¦¬(Distance)ë„ í™•ì¸í•˜ì„¸ìš”.
    * Case 1: ê±°ë¦¬ê°€ ê°€ê¹ë‹¤ â†’ Lossê°€ ë‚®ì€ ë†ˆë§Œ ë‚¨ê¹€ (Local Refinement).
    * Case 2: ê±°ë¦¬ê°€ ë©€ë‹¤ â†’ Lossê°€ í—ˆìš© ë²”ìœ„ ë‚´ë¼ë©´ ë‘˜ ë‹¤ ì‚´ë¦¼ (Global Exploration ìœ ì§€).


### Phase 3: ì •ë°€ ìµœì í™” (Hard Data Consistency)
* êµ¬ê°„: T=200 ~ 0 (ë§ˆì§€ë§‰ 20% êµ¬ê°„)
* ë™ì‘: Latent Optimization ON
    * ì´ì œ Repulsive Forceë¥¼ ë•ë‹ˆë‹¤ (ì„œë¡œ ë°€ì–´ë‚¼ í•„ìš” ì—†ìŒ).
    * ëŒ€ì‹  ReSampleì˜ Latent Optimizationì„ ì¼œì„œ, í˜„ì¬ ìœ„ì¹˜(z)ë¥¼ ì¸¡ì •ê°’(y)ì— ê°•í•˜ê²Œ(Hard) ë°€ì°©ì‹œí‚µë‹ˆë‹¤. DAPSë„ ê³„ì† ì¼­ë‹ˆë‹¤.
    * ì£¼ì˜: Pixel Optimizationì€ ì ˆëŒ€ ê¸ˆì§€ (Phase Retrievalì—ì„œëŠ” ë…ì…ë‹ˆë‹¤).
* ëª©ì : DAPSê°€ ë‚¨ê¸´ ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê³  PSNRì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.

ReSampleì´ í•„ìš”í•œ ìˆœê°„: "ë§ˆì§€ë§‰ í•œ ë¼˜ (Fine-tuning)"
TDPì˜ Particle Guidance(PG)ì™€ DAPSë¡œ ì—´ì‹¬íˆ íƒìƒ‰í•´ì„œ, ìš´ ì¢‹ê²Œ ì›ë³¸ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ í˜•íƒœ(Mode)ë¥¼ ì°¾ì•˜ë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤. í•˜ì§€ë§Œ DAPSëŠ” ë³¸ì§ˆì ìœ¼ë¡œ 'ë…¸ì´ì¦ˆë¥¼ ì„ëŠ”(Annealing)' ë°©ì‹ì´ê¸° ë•Œë¬¸ì—, ìµœì¢… ê²°ê³¼ë¬¼(t=0)ì—ë„ ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆê°€ ë‚¨ì•„ìˆê±°ë‚˜ ì¸¡ì •ê°’ yì™€ ì™„ë²½í•˜ê²Œ ì¼ì¹˜í•˜ì§€ëŠ” ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ë•Œ ReSampleì˜ "Latent Optimization"ì´ ë“±ì¥í•©ë‹ˆë‹¤.
* ì—­í• : "ì´ì œ í° ê·¸ë¦¼(ìœ„ìƒ, í˜•íƒœ)ì€ ë§ì•˜ìœ¼ë‹ˆ, ë…¸ì´ì¦ˆë¥¼ ë„ê³  ë””í…Œì¼ì„ ì¸¡ì •ê°’ yì— ê°•ì œë¡œ(Hard Consistency) ë§ì¶°ë¼."
* ì•ˆì „í•œ ì´ìœ : ì´ë¯¸ DAPS+TDPê°€ 'ì •ë‹µ ê·¼ì²˜(Basin of Attraction)'ê¹Œì§€ ë°ë ¤ë‹¤ ë†“ì•˜ê¸° ë•Œë¬¸ì—, ì´ì œëŠ” ìµœì í™”ë¥¼ ê°•í•˜ê²Œ ê±¸ì–´ë„ Local Minima(ì—‰ëš±í•œ í•´)ë¡œ ë¹ ì§€ì§€ ì•Šê³  Global Optima(ì§„ì§œ ì •ë‹µ)ë¡œ ì™ ë¹¨ë ¤ ë“¤ì–´ê°‘ë‹ˆë‹¤ 
* ReSampleì—ì„œë„ local proximity(ì •ë‹µì— ê°€ê¹Œìš´ ê³³) ì•ˆì—ì„œ optimiationì„ í•¨ìœ¼ë¡œì¨ local minimaì— ë¹ ì§€ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ DDIM unconditional x0 predictionì„ optimization initial pointë¡œ ì‚¼ì•˜ë˜ ê²ƒê³¼ ë¹„ìŠ·í•œ ë§¥ë½!
ReSample ì ìš© ì‹œì : $T=200$ (Low noise) ì‹œì ì€ ì´ë¯¸ ì´ë¯¸ì§€ê°€ ê±°ì˜ ë‹¤ ë§Œë“¤ì–´ì§„ ìƒíƒœì…ë‹ˆë‹¤. ì´ë•Œ ReSampleì˜ Optimizationì„ ë„ˆë¬´ ê°•í•˜ê²Œ(Learning rateë¥¼ ë†’ê²Œ) ê±¸ë©´, ê¸°ê» DAPSê°€ ë§Œë“¤ì–´ë†“ì€ ìì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤ì²˜ê°€ ë§ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "Weak Optimization"ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •ë§Œ í•˜ëŠ” ê²ƒì´ ë” ì•ˆì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.








## í”„ë¡œì íŠ¸ ê¸°ëŒ€ ê²°ê³¼: ë³´ë‹¤ ì ì€ ì—°ì‚°ìœ¼ë¡œ ë¹„ìŠ·í•˜ê±°ë‚˜ ë” ì¢‹ì€ ì„±ëŠ¥ì„!
- DAPSì—ì„œ Phase Retrievalì˜ ë¶ˆì•ˆì •ì„±ì„ ê³ ë ¤í•˜ì—¬, 4ë²ˆì˜ independent runsì„ ìˆ˜í–‰í•œ ë’¤ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ì„ íƒí•˜ì—¬ ë³´ê³ í–ˆìœ¼ë‹ˆ, ìš°ë¦¬í”Œì ì„ DAPS 4 runì´ë‘ ë¹„êµí–ˆì„ë•Œ ì‹œê°„xGPU ì‚¬ìš©ëŸ‰ì´ ë¹„ìŠ·í•˜ê±°ë‚˜ ì‘ìœ¼ë©´ì„œ ì„±ëŠ¥ì´ ë¹„ìŠ·í•˜ê±°ë‚˜ ë†’ìŒì„ ë³´ì´ë©´ ë˜ëŠ” ê²ƒ!
- ì‹¤í—˜ 2 (4 â†’ 2 Pruning)**ëŠ” ì´ë¡ ì  ìµœì ì (2 Modes)ê³¼ í˜„ì‹¤ì  ì•ˆì „ì¥ì¹˜(4 Runs) ì‚¬ì´ì˜ **"Sweet Spot"**ì„ ì°¾ëŠ” ì„¤ì •
- max ê°’ ë¿ë§Œ ì•„ë‹ˆë¼ std ë“± ë¶„í¬ë¥¼ ê°€ì§€ê³ ë„ ì˜ë¯¸ìˆëŠ” ë¶„ì„ì„ í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ.


## êµ¬í˜„ ê°€ì´ë“œ
- ëª¨ë“  Measurement Operator($\mathcal{A}$)ì™€ Loss Functionì€ (B, C, H, W) í˜•íƒœì˜ ì…ë ¥ì„ ë°›ì•„ **ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë³‘ë ¬ ì—°ì‚°(Broadcasting)**ì´ ê°€ëŠ¥í•˜ë„ë¡ ì‘ì„±ë˜ì–´ì•¼ í•œë‹¤. for ë£¨í”„ë¡œ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•˜ì§€ ë§ê³  PyTorchì˜ í…ì„œ ì—°ì‚°ì„ ì“¸ ê²ƒ!
- ìš°ë¦¬ëŠ” í•˜ë‚˜ì˜ $y$(ì¸¡ì •ê°’)ì— ëŒ€í•´ 2~4ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ $z_T$(ì´ˆê¸° ë…¸ì´ì¦ˆ)ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. Data Loaderì—ì„œ ì´ë¯¸ì§€ 1ì¥ì„ ê°€ì ¸ì˜¤ë©´, ì´ë¥¼ **batch_size=2~4ë¡œ ë³µì œ(repeat)**í•˜ë˜, ì´ˆê¸° ë…¸ì´ì¦ˆ $z_T$ëŠ” torch.randn(2~4, ...)ë¡œ ì„œë¡œ ë‹¤ë¥´ê²Œ ìƒì„±ë˜ë„ë¡ ì½”ë“œë¥¼ ì§¤ ê²ƒ!
- ~~ë³´í†µ Diffusion InferenceëŠ” with torch.no_grad(): ì•ˆì—ì„œ ë•ë‹ˆë‹¤. í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” **Repulsion($\nabla_z \Phi$)**ê³¼ ReSample Optimization($\nabla_z \|y - Ax\|^2$) ë•Œë¬¸ì— ì‹¤í—˜ 1~5ì—ì„œ Gradientê°€ í•„ìš”í•  ì˜ˆì •ì´ë‹¤. ë”°ë¼ì„œ, Samplerì˜ ë©”ì¸ ë£¨í”„ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ Gradient ê³„ì‚°ì´ ê°€ëŠ¥í•˜ë„ë¡ ì—´ì–´ë‘ê³ (enable_grad), í•„ìš”í•œ ë¶€ë¶„ì—ì„œë§Œ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ no_gradë¥¼ ì“°ê±°ë‚˜, í˜¹ì€ ë°˜ëŒ€ë¡œ no_grad ë² ì´ìŠ¤ì— íŠ¹ì • ìŠ¤í…(PG, Optimization)ì—ì„œë§Œ enable_gradë¥¼ ì¼œëŠ” í† ê¸€(Toggle) êµ¬ì¡°ë¥¼ ë¯¸ë¦¬ ì‹¤í—˜ 0ì—ì„œë¶€í„° ë§Œë“¤ì–´ì•¼ í•œë‹¤!~~ â†’ **ì™„ë£Œ**: `sampler.py`ì˜ `LatentDAPS.sample()`ì—ì„œ `torch.set_grad_enabled(step_needs_grad)` êµ¬ì¡° êµ¬í˜„. `do_repulsion`ê³¼ `do_optimization` flagë¡œ stepë³„ gradient í™œì„±í™” ì œì–´. ì‹¤í—˜ 1, 2, 4 ë¡œì§ì€ TODO ì£¼ì„ìœ¼ë¡œ ì¤€ë¹„ë¨.
- ~~ì‹¤í—˜ 0~5ë¥¼ ìŠ¤í¬ë¦½íŠ¸ í•˜ë‚˜ë¡œ ì œì–´í•˜ë ¤ë©´ Flag ì„¤ê³„ê°€ ì¤‘ìš”í•˜ë‹¤. ë‹¤ìŒ Argumentë“¤ì„ ë¯¸ë¦¬ ì •ì˜í•´ ë‘˜ ê²ƒ!~~ â†’ **ì™„ë£Œ**: `configs/default.yaml`ì— ì •ì˜ë¨
    - `num_samples` (int): í•œ ë²ˆì— ìƒì„±í•  ì…ì(ì´ë¯¸ì§€)ì˜ ê°œìˆ˜ (ê¸°ì¡´ DAPSì˜ num_samplesë¥¼ ê·¸ëŒ€ë¡œ í™œìš©, particle_num ì—­í• )
    - `repulsion_scale` (float): ì…ìë¼ë¦¬ ë°€ì–´ë‚´ëŠ” í˜ì˜ ì´ˆê¸° ê°•ë„. 0.0ì´ë©´ ë…ë¦½ ì‹¤í–‰ (DAPS baseline), >0.0ì´ë©´ ì„œë¡œ ë°€ì–´ëƒ„
    - `pruning_step` (int): ê°€ì§€ì¹˜ê¸° ìˆ˜í–‰ timestep. -1ì´ë©´ pruning ì—†ìŒ
    - `optimization_step` (int): latent optimization ì‹œì‘ timestep. -1ì´ë©´ optimization ì—†ìŒ
    - `use_tpu` (bool): TPU ì‚¬ìš© ì—¬ë¶€. falseë©´ CUDA, trueë©´ GCP TPU v3-8 (PyTorch XLA) ì‚¬ìš©. TPU ì‚¬ìš© ì‹œ `xm.mark_step()`ì´ ë§¤ sampling stepë§ˆë‹¤ í˜¸ì¶œë˜ì–´ lazy execution ê·¸ë˜í”„ê°€ ì‹¤í–‰ë¨.
    - (num_eval_imagesëŠ” data configì—ì„œ ì œì–´)
- ì‹¤í—˜ë³„ argument ì„¸íŒ… ê°€ì´ë“œ:
    Exp 0: Baseline (DAPS Replication)particle_num=4, repulsion_scale=0.0:ì´ë ‡ê²Œ ì„¤ì •í•˜ë©´ 4ê°œì˜ ì…ìê°€ ì„œë¡œ ê°„ì„­í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, DAPS ë…¼ë¬¸ì—ì„œ "1ê°œì”© 4ë²ˆ ëŒë¦° ê²ƒ(4 runs)"ê³¼ ìˆ˜í•™ì ìœ¼ë¡œ ì™„ì „íˆ ë™ì¼í•œ ê²°ê³¼ë¥¼ ëƒ…ë‹ˆë‹¤. (ì‹œë“œë§Œ ì˜ ì œì–´ëœë‹¤ë©´)ì´ê²ƒì´ ìš°ë¦¬ì˜ Reference ì„±ëŠ¥ì´ ë©ë‹ˆë‹¤.
    Exp 1: Repulsion Onlyrepulsion_scale > 0:ì´ì œ 4ê°œì˜ ì…ìê°€ ì„œë¡œ ë°€ì–´ëƒ…ë‹ˆë‹¤.ëª©í‘œ: Exp 0ë³´ë‹¤ **ë‹¤ì–‘ì„±(Std)**ì´ ë†’ê³ , **ìµœê³ ì (Max PSNR)**ì´ ë†’ê²Œ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    Exp 2: Efficiency (Pruning)pruning_step=200:ì½”ë“œëŠ” $t=200$ì´ ë˜ëŠ” ìˆœê°„, Lossì™€ Distanceë¥¼ ê³„ì‚°í•˜ì—¬ **4ê°œ ì¤‘ 2ê°œë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œ(ë˜ëŠ” Masking)**í•´ì•¼ í•©ë‹ˆë‹¤.ëª©í‘œ: Exp 1ê³¼ ì„±ëŠ¥ì€ ë¹„ìŠ·í•œë°, **ì‹œê°„(Time)ê³¼ ë©”ëª¨ë¦¬(VRAM)**ê°€ ì¤„ì–´ë“œëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    Exp 4: Quality (Optimization)optimization_step=200:$t=1000 \to 201$ê¹Œì§€ëŠ” Repulsionìœ¼ë¡œ íƒìƒ‰í•˜ê³ ,$t=200 \to 0$ë¶€í„°ëŠ” Repulsionì„ ë„ê³ (scale=0 ê°•ì œ ì ìš©), Latent Optimizationì„ ì¼­ë‹ˆë‹¤.ëª©í‘œ: Exp 2ë³´ë‹¤ PSNRì´ í™•ì‹¤íˆ ë” ì˜¬ë¼ê°€ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
- metric.jsonì— phaseë³„ time, gpu, optimization íšŸìˆ˜/ì‹œê°„ì„ ê¸°ë¡í•  ê²ƒ
- metric.jsonì„ Parsingí•˜ëŠ” ì½”ë“œë¥¼ ë§Œë“¤ ê²ƒ
- ì½”ë“œ ì‹¤í–‰ì„ í†µí•œ sanity checkëŠ” GPU/TPUê°€ ë‹¬ë¦° ì„œë²„ì—ì„œ ì§„í–‰í•  ì˜ˆì •! (ë¡œì»¬ ë§¥ë¶ X)
- TODOë¥¼ ì™„ë£Œí•œ ê²½ìš° ì´ PROJECT.md íŒŒì¼ì— ì·¨ì†Œì„ ì„ ê·¸ì–´ í‘œì‹œí•  ê²ƒ! ë§Œì•½ ë…¼ì˜ ê²°ê³¼ md ì„¤ëª…ë³´ë‹¤ ë” ì í•©í•œ ì„ íƒì§€ê°€ ìˆì–´ì„œ ì‹¤ì œ êµ¬í˜„ì— ì°¨ì´ê°€ ìƒê¸´ ê²½ìš° PROJECT.mdë¥¼ ì—…ë°ì´íŠ¸í•  ê²ƒ!
- git commit messageëŠ” í•œ/ì˜ í˜¼ìš© ê°€ëŠ¥, ì‹¤í—˜ ëª‡ì„ ì¤€ë¹„í•˜ê³  ìˆëŠ”ì§€ ëª…ì‹œ, í•œ ì¤„ ì´ë‚´ë¡œ ì‘ì„±. commitì€ vscode guië¡œë§Œ ì§„í–‰
- í˜„ í´ë”ëŠ” DAPS ë ˆí¬ë¥¼ ë² ì´ìŠ¤ë¡œ ìˆ˜ì • ì¤‘ì— ìˆìœ¼ë©°, TDP ë° ReSample ê´€ë ¨ ì„¸ë¶€ì‚¬í•­ì€ ì¶”í›„ í•´ë‹¹ ì‹¤í—˜ êµ¬í˜„ ë‹¨ê³„ì—ì„œ ì¶”ê°€ ì˜ˆì •
- ~~command íŒŒì¼ë“¤ì— ìƒˆë¡œìš´ argumentë“¤ ë°˜ì˜ ë° 1/10/100 imageìš© command ì¶”ê°€~~ â†’ **ì™„ë£Œ**: í´ë” êµ¬ì¡°:
    - `commands_gpu/`: GPU (CUDA) ì „ìš© ëª…ë ¹ì–´ (use_tpu=false)
    - `commands_tpu/`: TPU (PyTorch XLA) ì „ìš© ëª…ë ¹ì–´ (use_tpu=true)
    - ê° í´ë”ì— `exp0_baseline.sh` ~ `exp5_final.sh` í¬í•¨
    - ëª¨ë“  commandì— `repulsion_scale`, `pruning_step`, `optimization_step`, `data.end_id` ë°˜ì˜
    - TPU ë²„ì „ì€ `gpu=0` ëŒ€ì‹  `use_tpu=true`, save_dir/nameì— `_tpu` suffix ì¶”ê°€